# -*- coding: utf-8 -*-
"""FedResilience.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uDUkmgapG0UfBKYmFXVAJJi9p2fogC-0
"""



import urllib.request

#pip uninstall pillow

#pip install pillow==4.0.0

#pip install --user syft==0.2.9
#the code will show error if the syft version is 0.3.*.

def download_url(url, save_as):
    response = urllib.request.urlopen(url)
    data = response.read()
    file = open(save_as, 'wb')
    file.write(data)
    file.close()
    response.close()
    
def read_binary_file(file):
    f = open(file,'rb')
    block = f.read()
    return block.decode('utf-16')

def split_text_in_lines(text):
    return text.split('\r\n')

def split_by_tabs(line):
    return line.split('\t')

#data_link = 'https://drive.google.com/uc?export=download&id=1J1H2ZYBPRlXNKKWJ1CjdHlRqn4AW0jSi'
data_link = 'https://drive.google.com/uc?export=download&id=1QTTCnSHNxexsS6-lGQBPv8Jui_gQ5DE1'
FedResilience_data = 'FedResilience.data'
b= download_url(data_link, FedResilience_data)

import numpy as np

def parse_double(field):
    field = field.replace(',', '.')
    return float(field)

def parse_boolean(field):
    return 1. if field == 'yes' else 0.

def read_np_array(file = FedResilience_data):
    text = read_binary_file(file)
    lines = split_text_in_lines(text)
    rows = []
    for line in lines:
        if line == '': continue
        line = line.replace('\r\n', '')
        fields = split_by_tabs(line)
        row = []
        j = 0
        for field in fields:
            if j==0:
              value = parse_double(field)
            else:
              value = parse_boolean(field) 
            row.append(value)
            j += 1
        rows.append(row)
    matrix = np.array(rows, dtype = np.float32)
    return matrix

def get_random_indexes(n):
    indexes = list(range(n))
    random_indexes = []
    for i in range(n):
        r = np.random.randint(len(indexes))
        random_indexes.append(indexes.pop(r))
    return random_indexes

def get_indexes_for_2_datasets(n, training = 80):
    indexes = get_random_indexes(n)
    train = int(training / 100. * n)
    return indexes[:train], indexes[train:]

matrix = read_np_array()
n_samples, n_dimensions = matrix.shape

train_indexes, test_indexes = get_indexes_for_2_datasets(n_samples)
train_data = matrix[train_indexes]
test_data = matrix[test_indexes]

def print_dataset(name, data):
    print('Dataset {}. Shape: {}'.format(name, data.shape))
    print(data)

print_dataset('Train', train_data)

print_dataset('Test', test_data)

import tensorflow as tf

tf.__version__

import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F

input_size = 6
learning_rate = 0.01
num_iterations = 2000

class LogisticRegression(torch.nn.Module):

    def __init__(self):
        super(LogisticRegression, self).__init__()
        self.linear = torch.nn.Linear(input_size, 1)

    def forward(self, x):
        return torch.sigmoid(self.linear(x))

def decide(y):
    return 1 if y >= 0.5 else 0

decide_vectorized = np.vectorize(decide)

to_percent = lambda x: '{:.2f}%'.format(x)

def compute_accuracy(model, input, output):
    prediction = model(input).data.numpy()[:, 0]
    n_samples = prediction.shape[0] + 0.
    prediction = decide_vectorized(prediction)
    equal = prediction == output.data.numpy()
    return 100. * equal.sum() / n_samples

def get_input_and_output(data):
    input = Variable(torch.tensor(data[:, :6], dtype = torch.float32))
    output1 = Variable(torch.tensor(data[:, 6], dtype = torch.float32))
    output2 = Variable(torch.tensor(data[:, 7], dtype = torch.float32))
    return input, output1, output2

input, output1, output2 = get_input_and_output(train_data)
test_input, test_output1, test_output2 = get_input_and_output(test_data)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

FedResilience_title1 = 'Predict Outage'
FedResilience_title2 = 'Predict Resouce-sharing Information'

def plot_graphs(FedResilience_title, losses, accuracies):
    plt.plot(losses)
    plt.title(f"{FedResilience_title} - Training Loss")
    plt.xlabel("Iterations")
    plt.ylabel("Training Loss")
    plt.show()
    plt.plot(accuracies)
    plt.title(f"{FedResilience_title} - Training Accuracy")
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy (Percent %)")
    plt.show()

def train_model(FedResilience_title, input, output, test_input, test_output):
    model = LogisticRegression()
    criterion = torch.nn.BCELoss(size_average=True)
    #criterion = torch.nn.LogSoftmax(model)
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  
    losses = []
    accuracies = []
    n_samples, _ = input.shape
    for iteration in range(num_iterations):
            optimizer.zero_grad()
            prediction = model(input)
           
            output = output.reshape(-1,1)
            output = output.float()
            loss = criterion(prediction, output)
            loss.backward()
            optimizer.step()
            if iteration % 10 == 0:
                train_acc = compute_accuracy(model, input, output)
                train_loss = loss.item()
                losses.append(train_loss)
                accuracies.append(train_acc)
                print('iteration={}, loss={:.4f}, train_acc={}'.format(iteration, train_loss, to_percent(train_acc)))
    plot_graphs(FedResilience_title, losses, accuracies)
    test_acc = compute_accuracy(model, test_input, test_output)
    print('\nTesting Accuracy = {}'.format(to_percent(test_acc)))
    return model

model = train_model(FedResilience_title1, input, output1, test_input, test_output1)

model = train_model(FedResilience_title2, input, output2, test_input, test_output2)

pip install --user syft==0.2.9

import syft as sy
import torch as th
hook = sy.TorchHook(th)
from torch import nn, optim

n_Agents = 5
Agents = []

for i in range(n_Agents):
    Agent_name = 'Agent{}'.format(i)
    Agent = sy.VirtualWorker(hook, id = Agent_name)
    Agents.append(Agent)
secure_worker = sy.VirtualWorker(hook, id="secure_worker")

def get_workers_names(workers):
    return [worker.id for worker in workers]

def add_and_print_workers(worker, workers):
    print('workers of {} = {}'.format(worker.id, get_workers_names(workers)))
    worker.add_workers(workers)

for i in range(n_Agents):
    workers = [Agents[i2] for i2 in range(n_Agents) if i2 != i] + [secure_worker]
    add_and_print_workers(Agents[i], workers)
add_and_print_workers(secure_worker, Agents)

n_samples = train_data.shape[0]
samples_per_Agent = int((n_samples + 0.5) / n_Agents)
Agent_features = []
Agent_targets1 = []
Agent_targets2 = []
train_data = th.tensor(train_data, dtype = torch.float32, requires_grad=True)
for i in range(n_Agents):
    train_data2 = train_data[i * samples_per_Agent:(i + 1) * samples_per_Agent].clone().detach().requires_grad_(True)
    features = train_data2[:, :6].clone().detach().requires_grad_(True)
    targets1 = train_data2[:, 6][:, None].clone().detach() 
    targets2 = train_data2[:, 7][:, None].clone().detach() 
    Agent_features.append(features.send(Agents[i]))
    Agent_targets1.append(targets1.send(Agents[i]))
    Agent_targets2.append(targets2.send(Agents[i]))

print(model)

def plot_federated_graphs(FedResilience_title, losses, accuracies):
    for i in range(n_Agents):
        plt.plot(losses[i], label=f'Critical Infrastructure Agent {i}')
    legend = plt.legend(loc='upper right', shadow=True)
    plt.title(f"{FedResilience_title} - Training Loss")
    plt.xlabel("Iterations")
    plt.ylabel("Training Loss")
    plt.show()
    for i in range(n_Agents):
        plt.plot(accuracies[i], label=f'Critical Infrastructure Agent {i}')
    legend = plt.legend(loc='lower right', shadow=True)
    plt.title(f"{FedResilience_title} - Training Accuracy")
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy (Percent %)")
    plt.show()

def compute_federated_accuracy(model, input, output):
    prediction = model(input)
    n_samples = prediction.shape[0]
    s = 0.
    for i in range(n_samples):
        p = 1. if prediction[i] >= 0.5 else 0.
        e = 1. if p == output[i] else 0.
        s += e
    return 100. * s / n_samples

iterations = 500 #2000
worker_iterations = [2, 0, 0, 0, 0]

worker_iterations[0]

from google.colab import drive
drive.mount('/content/gdrive')

def federated_learning(FedResilience_title, Agent_features, Agent_targets, test_input, test_output):
    model = LogisticRegression()
    
    criterion = torch.nn.BCELoss(size_average=True)
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  
    losses = [[] for i in range(n_Agents)]
    accuracies = [[] for i in range(n_Agents)]
    for iteration in range(iterations+1):
        models = [model.copy().send(Agents[i]) for i in range(n_Agents)]
        optimizers = [torch.optim.SGD(params = models[i].parameters(), lr = learning_rate) for i in range(n_Agents)]
        j=-1
        last_losses = []
        for i in range(n_Agents):
          j=j+1
          for worker_iteration in range(worker_iterations[j]): 
                optimizers[i].zero_grad()
                prediction = models[i](Agent_features[i])
                loss = criterion(prediction, Agent_targets[i])
                loss.backward()
                optimizers[i].step()
                loss = loss.get().data.item()
          last_losses.append(loss)
        for i in range(n_Agents):
            losses[i].append(last_losses[i])
            train_acc = compute_federated_accuracy(models[i], Agent_features[i], Agent_targets[i])
            accuracies[i].append(train_acc)
            models[i].move(secure_worker)
        with th.no_grad():
            avg_weight = sum([models[i].linear.weight.data for i in range(n_Agents)]) / n_Agents
            model.linear.weight.set_(avg_weight.get())
            avg_bias = sum([models[i].linear.bias.data for i in range(n_Agents)]) / n_Agents
            model.linear.bias.set_(avg_bias.get())
        if iteration % 5 == 0:
            losses_str = ['{:.4f}'.format(losses[i][-1]) for i in range(n_Agents)]
            accuracies_str = [to_percent(accuracies[i][-1]) for i in range(n_Agents)]
            print('Iteration={}, losses={}, accuracies={}'.format(iteration, losses_str, accuracies_str))
            if(FedResilience_title == 'Predict Outage'):
              with open('/content/gdrive/My Drive/FL Agent/Output/Latest/FedResilience_5_3_Agents_Outage.txt', 'a') as f:
                #f.write('Iteration={}, losses={}, accuracies={}\n'.format(iteration, losses_str, accuracies_str))
                #f.write('{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\n'.format(iteration, losses_str[0],losses_str[1],losses_str[2],losses_str[3], losses_str[4],losses_str[5],losses_str[6], losses_str[7], accuracies_str[0],
                #                                          accuracies_str[1], accuracies_str[2], accuracies_str[3], accuracies_str[4], accuracies_str[5], accuracies_str[6], accuracies_str[7]))
                f.write('{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\n'.format(iteration, losses_str[0],losses_str[1],losses_str[2],losses_str[3], losses_str[4], accuracies_str[0],
                                                          accuracies_str[1], accuracies_str[2], accuracies_str[3], accuracies_str[4]))
               # f.write('{}, {}, {}, {}, {}, {}, {}\n'.format(iteration, losses_str[0],losses_str[1], losses_str[2], accuracies_str[0],
            #                                              accuracies_str[1], accuracies_str[2]))
           
            if(FedResilience_title == 'Predict Resouce-sharing Information'):
              with open('/content/gdrive/My Drive/FL Agent/Output/Latest/FedResilience_5_3_Agents_Resource.txt', 'a') as f:
                #f.write('Iteration={}, losses={}, accuracies={}\n'.format(iteration, losses_str, accuracies_str))
                f.write('{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\n'.format(iteration, losses_str[0],losses_str[1],losses_str[2],losses_str[3], losses_str[4], accuracies_str[0],
                                                          accuracies_str[1], accuracies_str[2], accuracies_str[3], accuracies_str[4]))
                #f.write('{}, {}, {}, {}, {}, {}, {}\n'.format(iteration, losses_str[0],losses_str[1], losses_str[2], accuracies_str[0],
                    #                                      accuracies_str[1], accuracies_str[2]))
    plot_federated_graphs(FedResilience_title, losses, accuracies)
    test_acc = compute_accuracy(model, test_input, test_output)
    print('\nTesting Accuracy = {}'.format(to_percent(test_acc)))
    j=0
    return model

model = federated_learning(FedResilience_title1, Agent_features, Agent_targets1, test_input, test_output1)

model = federated_learning(FedResilience_title2, Agent_features, Agent_targets2, test_input, test_output2)